---
title: "Homework 1"
author: "Han Siyue 17307110012"
date: "2019/10/1"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Exercise 3.3

Derive the probability inverse transformation of Pareto(a, b)

Because $F(x) = 1 − (\frac{b}{x})^a$, we can get
$$
\begin{align}
F^{-1}(u) &= inf\{x: F(x)\ge u\}\ (0\le u\le 1)\\ &= inf\{x: (\frac{b}{x})^a \le 1-u\}\ (0\le u\le 1)\\ &= \frac{b}{(1-u)^{1/a}}
\end{align}
$$
Using the inverse transform method to simulate a random sample from the Pareto(2, 2)
```{r}
a <- 2
b <- 2
n <- 1000
u <- runif(n)
x <- b / (1 - u)^(1 / a)
f<- function(x)  return(8*x^(-3))
hist(x, prob = TRUE, main = expression(f(x)==8*x^{-3}))
curve(f, add = TRUE)
```

### Exercise 3.5

With the pmf, we can get 

\begin{equation}
F(x)=\left\{
\begin{array}{lr}
0\ &,&\quad x<0& \\
0.1\ &,&\quad 0\le x<1& \\
0.3\ &,&\quad 1\le x<2& \\
0.5\ &,&\quad 2\le x<3& \\
0.7\ &,&\quad 3\le x<4& \\
1\ &,&\quad x\ge 4&
\end{array}
\right.

{\rm and\ thus\ },\ F^{-1}(u)=\left\{
\begin{array}{lr}
0\ &,&\quad 0\le u \le 0.1& \\
1\ &,&\quad 0.1< u\le 0.3& \\
2\ &,&\quad 0.3< u\le 0.5& \\
3\ &,&\quad 0.5< u\le 0.7& \\
4\ &,&\quad 0.7< u\le 1\ \ \ & \\
\end{array}
\right.
\end{equation}

Using the inverse transform method to generate a random sample of size 1000:
```{r}
n <- 1000
u <- runif(n)
x <- c()
for (i in 1:n) {
  if (u[i] <= 0.1)
    x[i] <- 0
  else if (u[i] <= 0.3)
    x[i] <- 1
  else if (u[i] <= 0.5)
    x[i] <- 2
  else if (u[i] <= 0.7)
    x[i] <- 3
  else
    x[i] <- 4
}
table(x)/n
```

Repeat using the R sample function:
```{r}
population <- c(0, 1, 1, 2, 2, 3, 3, 4, 4, 4)
x <- sample(population, n, replace = TRUE)
table(x)/n
```

### Exercise 3.6

Prove that the accepted variates generated by the acceptance-rejection sampling algorithm are a random sample from the target density $f_X$.

pf:
$$
\begin{align}
&P(accept|Y)=P(u<\frac{f(Y)}{cg(Y)}|Y)=\frac{f(Y)}{cg(Y)}\\
&P(accept)=\int^\infty_{-\infty} P(accept|Y=y)f_Y(y){\rm d}y
=\int^\infty_{-\infty}\frac{f(y)}{cg(y)}g(y){\rm d}y=\frac{1}{c}\int^\infty_{-\infty}f(y){\rm d}y=\frac{1}{c}\\
&F_X(y)=P(Y\le y|accept)=\frac{P(accept|Y=y)P(Y\le y)}{P(accept)}=\frac{\frac{f(y)}{cg(y)}P(Y\le y)}{\frac{1}{c}}=\frac{f(y)}{g(y)}F_Y(y)\\
&\therefore f_X(y)=\frac{f(y)}{g(y)}f_Y(y)=\frac{f(y)}{g(y)}g(y)=f(y)\quad \rm{Q.E.D.}
\end{align}
$$

### Exercise 3.7

Write a function to generate a random sample of size n from the Beta(a, b) distribution by the acceptance-rejection method.
```{r}
beta_by_acc_rej <- function(a, b){
  n <- 1000
  k <- 0      #counter for accepted
  j <- 0      #iterations
  y <- numeric(n)

  while (k < n) {
    u <- runif(1)
    j <- j + 1
    x <- runif(1)  #random variate from g
    if (x^(a-1) * (1-x)^(b-1) > u) {
      #we accept x
      k <- k + 1
      y[k] <- x
    }
  }
  return(y)
}
```
Generate a random sample of size 1000 from the Beta(3,2) distribution. Graph the histogram of the sample with the theoretical Beta(3,2) density superimposed.
```{r}
beta32_pdf <- function(x){
  gam <- gamma(5) / (gamma(3) * gamma(2))
  exp <- x^2 * (1-x)
  return(gam * exp)
}

y <- beta_by_acc_rej(3, 2)
hist(y, prob = TRUE, main = "Beta(3, 2)")
curve(beta32_pdf, add = TRUE)
```

### Exercise 3.12
Simulate a continuous Exponential-Gamma mixture. Suppose that the rate parameter Λ has Gamma(r, β) distribution and Y has Exp(Λ) distribution. Generate 1000 random observations from this mixture with r = 4 and β = 2.
```{r}
n <- 1000
y <- numeric(n)
for (i in 1:n) {
  lambda <- rgamma(1, 4, 2)
  y[i] <- rexp(1, lambda)  #the mixture
}
```

### Exercise 3.13
The pdf of a Pareto distribution is $f(y)=\frac{\gamma\beta^\gamma}{(\beta+y)^{\gamma+1}}$
```{r}
pareto42_pdf <- function(x) return(64 / (x+2)^5)
hist(y, prob = TRUE, main = "Pareto(4, 2)")
curve(pareto42_pdf, add = TRUE)
```

### Exercise 3.14
```{r}
rmvn.Choleski <- function(n, mu, Sigma) {
  # generate n random vectors from MVN(mu, Sigma)
  # dimension is inferred from mu and Sigma
  d <- length(mu)
  Q <- chol(Sigma) # Choleski factorization of Sigma
  Z <- matrix(rnorm(n*d), nrow=n, ncol=d)
  X <- Z %*% Q + matrix(mu, n, d, byrow=TRUE)
  X
}

n <- 200
mu <- c(0, 1, 2)
Sigma <- matrix(c(1.0, -0.5, 0.5, -0.5, 1.0, -0.5, 0.5, -0.5, 1.0), nrow = 3, ncol = 3)
X <- rmvn.Choleski(n, mu, Sigma)
pairs(X[, c(1, 2)], c("var 1", "var 2"))
pairs(X[, c(1, 3)], c("var 1", "var 3"))
pairs(X[, c(2, 3)], c("var 2", "var 3"))
```

The location and correlation approximately agree with the theoretical parameters of the corresponding bivariate normal distribution, which is -0.5, 0.5, -0.5, respectively.
